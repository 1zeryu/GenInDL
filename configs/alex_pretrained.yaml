epoch: 80
grad_clip: 3
log_frequency: 50
target_layer: features.10

model: 
  name: AlexNet_fine_tuning 
  num_classes: 10

dataset:
  name: DatasetGenerator
  train_bs: 128
  eval_bs: 128

criterion:
  name: CrossEntropyLoss

optimizer:
  name: SGD
  lr: 0.01
  weight_decay: 5.e-4
  momentum: 0.9

scheduler:
  name: ExponentialLR
  gamma: 0.9
