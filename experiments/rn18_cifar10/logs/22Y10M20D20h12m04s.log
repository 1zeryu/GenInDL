2022-10-20 20:12:04,889 seed: 0
2022-10-20 20:12:04,889 exp: rn18_cifar10
2022-10-20 20:12:04,889 if_logger: True
2022-10-20 20:12:04,890 if_writer: False
2022-10-20 20:12:04,890 load_model: state_dict
2022-10-20 20:12:04,890 only_test: False
2022-10-20 20:12:04,890 save: False
2022-10-20 20:12:04,891 epoch: 100
2022-10-20 20:12:04,891 grad_clip: -1
2022-10-20 20:12:04,891 log_frequency: 250
2022-10-20 20:12:04,891 model: Config([('name', 'ResNet18'), ('num_classes', 10)])
2022-10-20 20:12:04,891 dataset: Config([('name', 'DatasetGenerator'), ('train_bs', 128), ('eval_bs', 128)])
2022-10-20 20:12:04,891 criterion: Config([('name', 'CrossEntropyLoss')])
2022-10-20 20:12:04,892 optimizer: Config([('name', 'SGD'), ('lr', 0.1), ('weight_decay', 0.0005), ('momentum', 0.9)])
2022-10-20 20:12:04,892 scheduler: Config([('name', 'MultiStepLR'), ('milestones', [45, 75, 90]), ('gamma', 0.1)])
2022-10-20 20:12:07,213 state_dict loaded from experiments\rn18_cifar10\state_dict\state_dict.pt
2022-10-20 20:12:07,213 !!! The best accuracy is 0 !!!
2022-10-20 20:12:07,214 ====================Training Epoch 0====================
2022-10-20 20:12:10,335 epoch=0 global_step=0 loss=0.4611 loss_avg=0.4611 lr=0.1000 |gn|=0.0000 acc=0.8281 acc_avg=0.8281 time=0.32it/s
2022-10-20 20:12:43,300 epoch=0 global_step=250 loss=0.2519 loss_avg=0.3330 lr=0.1000 |gn|=0.0000 acc=0.8750 acc_avg=0.8863 time=9.35it/s
2022-10-20 20:13:02,242 ====================Eval Epoch 0====================
2022-10-20 20:13:05,751 [33mVal Loss: 0.50[0m
2022-10-20 20:13:05,752 [33mVal Acc: 0.8340[0m
2022-10-20 20:13:05,752 ====================Training Epoch 1====================
2022-10-20 20:13:20,273 epoch=1 global_step=500 loss=0.4735 loss_avg=0.3278 lr=0.1000 |gn|=0.0000 acc=0.8281 acc_avg=0.8883 time=9.35it/s
2022-10-20 20:13:53,366 epoch=1 global_step=750 loss=0.3701 loss_avg=0.3304 lr=0.1000 |gn|=0.0000 acc=0.8828 acc_avg=0.8877 time=9.43it/s
2022-10-20 20:13:57,412 ====================Eval Epoch 1====================
2022-10-20 20:14:00,803 [33mVal Loss: 0.58[0m
2022-10-20 20:14:00,804 [33mVal Acc: 0.8101[0m
2022-10-20 20:14:00,804 ====================Training Epoch 2====================
